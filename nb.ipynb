{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clonr local\n",
    "\n",
    "This notebook is meant to be able to run a local version of Clonr, without having to worry about all of the backend stuff, like rate limiting, caching, threading, async, background tasks, databases, metric tracking, postgres servers, authentication, api keys, ... yeah, lots of crap.\n",
    "\n",
    "Check out our prompt schematic on the doc to get an idea of the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innate traits\n",
    "\n",
    "The first step in clone creation is to define some basic fields. In the Frontend app, the clone creation process would look like one of those progress screens, where there's a bar at the top that fills up as you progress, and each page is one step.\n",
    "\n",
    "Here, we define things that should pretty much never change. They're fundamental enough that on the backend we will store them as columns of the Clone model in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone name\n",
    "char = 'Makima'\n",
    "\n",
    "# A single sentence tagline description. no more than like 20 tokens.\n",
    "short_description = 'Makima is the leader of the Public Safety Devil Hunter organization, and also the Control Devil.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long description\n",
    "\n",
    "This can be input by users, or auto-generated using the LLM. The idea here, is that some users might want to curate a public persona, and not have this auto-inferred. We can also do a 50/50 setup, letting users write in a partial answer, then asking the LLM to correct it, or fill in more details.\n",
    "\n",
    "We auto-generated the Makima description. Auto-generation works by iteratively querying all of the documents uploaded later (wiki, dialogues, youtube videos, websites). It is seede with the initial short_description, or the initial long_description if that exists.\n",
    "\n",
    "__user-created__: under clonr/data/icebreakers.py, we list a series of questions that users can use to help them write their long descriptions. We also give some examples in the prompt template for the LongDescription template.\n",
    "\n",
    "__data structures__: the __document__ is the main data structure. It just wraps some uploaded text (content) and acts as a single parent node for a list of chunks/nodes that will be generated when indexing our data. Indexing is overly fancy here, it just means chunking up the data and feeding it to a vectordb. The structured chunks are called __nodes__ and can contain parent and child elements that refer to other nodes (i.e. tree structure).\n",
    "\n",
    "Below, we give the code for using the Makima wiki page to iteratively generate a summary. Note, it takes two runs to compute. we want to max out the context length if possible when running this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathankernes/miniconda3/envs/jonny/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/jonathankernes/startups/clonr/clonr/text_splitters.py:33: UserWarning: Spacy was not found. `pip install spacy` and check that the en_core_web_sm pipeline is loaded.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from clonr.templates.long_description import LongDescription\n",
    "from clonr.data.load_examples import load_makima_data\n",
    "from clonr.data_structures import Document, Node\n",
    "from clonr.tokenizer import Tokenizer\n",
    "from clonr.llms import OpenAIModelEnum\n",
    "from clonr.text_splitters import TokenSplitter, SentenceSplitter\n",
    "from clonr.llms import MockLLM, GenerationParams\n",
    "from clonr.data.parsers import BasicWebParser\n",
    "\n",
    "llm = MockLLM()\n",
    "tokenizer = Tokenizer.from_openai(OpenAIModelEnum.chatgpt_0613)\n",
    "splitter = TokenSplitter(tokenizer=tokenizer, chunk_size=128, chunk_overlap=32)\n",
    "\n",
    "# this goes into the prompt\n",
    "document_type = 'wiki page'\n",
    "\n",
    "# we seed with the short if long is not partially filled.\n",
    "current_description = short_description\n",
    "\n",
    "# # We can parse from the internet, but it's not 100% cleaned\n",
    "# # This is just to demonstrate how this would work in general.\n",
    "# parser = BasicWebParser()\n",
    "# unfiltered_content = parser.extract(url='https://chainsaw-man.fandom.com/wiki/Makima')\n",
    "\n",
    "# load the pre-downloaded wiki page with a little bit of cleaning (mostly chopping the footnotes out.)\n",
    "chunks = splitter.split(Document(content=load_makima_data()))\n",
    "\n",
    "# Actually run the iterations. We log all calls to the LLM for debugging, but only the last\n",
    "# matters. Also, the other calls help count final tokens.\n",
    "# Don't worry, this cell won't cost money, it's the MockLLM.\n",
    "calls = []\n",
    "for chunk in chunks:\n",
    "    # max length constraint is ctx_length - 432 (prompt) - chunk_size - 2 * summary_size > 0\n",
    "    prompt = LongDescription.render_instruct(\n",
    "        document_type=document_type,\n",
    "        document_content=chunk,\n",
    "        current_description=current_description\n",
    "    )\n",
    "    params = GenerationParams(max_tokens=768, top_p=0.95, temperature=0.7)\n",
    "    r = await llm.agenerate(prompt, params=params)\n",
    "    current_description = r.content\n",
    "    calls.append(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result is precomputed. You can see the calls in data/assets/makima-description-calls.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token usage -- short: 20. long: 445\n"
     ]
    }
   ],
   "source": [
    "\n",
    "long_description = \"\"\"Makima is a complex and manipulative individual who leads the Public Safety Devil Hunter organization and also serves as the Control Devil. Her personality is characterized by extreme cunning, ruthlessness, and a Machiavellian approach to achieving her goals. She presents herself as friendly and relaxed, wearing a smile even in the midst of crises, but this is merely a fa√ßade to manipulate and control those around her. At the core of Makima's desires is a yearning for a sense of family and a longing to be together with Pochita, the Chainsaw Devil. She idolizes Chainsaw Man and seeks to bring him under her control, envisioning an ideal world without fear, death, and \"bad\" movies. Makima's willingness to sacrifice anyone, including herself, to achieve her goals demonstrates her dedication and determination. Her relationships are intricate and manipulative. She shows genuine affection only towards Pochita, viewing him as an equal due to his legendary status and power. Makima's interactions with Denji, the protagonist, are part of a calculated plan to break his contract with Pochita and regain control over him. Initially, she appears generous and creates a familial bond with Denji, but her true intentions are to plunge him into despair by attacking his personal relationships. Makima possesses supernatural abilities as a Devil, making her one of the strongest individuals in the world of Chainsaw Man. She has the power to make contracts with humans and control them, manipulating their memories and personalities. Her combat skills are formidable, as she defeated a weakened Pochita and ripped his heart from his body. Despite her invincible nature, she has faced opposition from various factions around the world. Overall, Makima's core characteristics include her calculating and manipulative personality, her yearning for control over Chainsaw Man, and her willingness to sacrifice others to achieve her goals. She possesses immense physical strength, enhanced smell, and a variety of supernatural abilities. Her control over others extends to their memories and personalities, and she is capable of remote communication, travel, and offensive attacks. While she may appear invulnerable, she has faced death multiple times, only to be revived due to the revival ability of Devils.\"\"\"\n",
    "\n",
    "print(f\"Token usage -- short: {tokenizer.length(short_description)}. long: {tokenizer.length(long_description)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikis and fact uploads\n",
    "\n",
    "The next part is uploading all of the facts and knowledge that describe the Clone. These will be stored and retrieved when necessary. A missing piece here, is the hookup to a social media platform. We need to add in an image to text model to create descriptions of posts, and to also timestamp and pair with captions. That creates the immersive live clone environment for some users.\n",
    "\n",
    "The strategy here is to chunk and upload to vector database. We made a simple in-memory vector database with no external dependencies except for numpy and onnx to use here. There are quite a few options in terms of chunking and indexing. For chunking, refer to the TextSplitter.py file in processing. SentenceSplitter works well on english, but it requires nltk and also produces un-even chunk sizes.\n",
    "\n",
    "For indexing, we wrote extensively in the README.md about differnt methods. The simplest and default is just standard chunking, i.e. what we call the ListIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-06 15:06:22.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclonr.index\u001b[0m:\u001b[36mabuild\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mCreating leaf nodes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from clonr.data.load_examples import load_makima_data\n",
    "from clonr.data_structures import Document, Node\n",
    "from clonr.tokenizer import Tokenizer\n",
    "from clonr.llms import OpenAIModelEnum\n",
    "from clonr.index import ListIndex, TreeIndex\n",
    "from clonr.text_splitters import TokenSplitter, SentenceSplitter\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer.from_openai(OpenAIModelEnum.chatgpt_0613)\n",
    "splitter = TokenSplitter(tokenizer=tokenizer, chunk_size=128, chunk_overlap=32)\n",
    "\n",
    "text = load_makima_data()\n",
    "doc = Document(content=text)\n",
    "\n",
    "list_index = ListIndex(tokenizer=tokenizer, splitter=splitter)\n",
    "nodes = await list_index.abuild(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-06 15:06:23.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclonr.index\u001b[0m:\u001b[36mabuild\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mCreating leaf nodes\u001b[0m\n",
      "\u001b[32m2023-07-06 15:06:23.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclonr.index\u001b[0m:\u001b[36m_process_level\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mLLM CALL: Depth 0. Group: 1/2. Total Tokens: 0.\u001b[0m\n",
      "\u001b[32m2023-07-06 15:06:23.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclonr.index\u001b[0m:\u001b[36m_process_level\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mLLM CALL: Depth 0. Group: 2/2. Total Tokens: 3433.\u001b[0m\n",
      "\u001b[32m2023-07-06 15:06:23.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclonr.index\u001b[0m:\u001b[36m_process_level\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mLLM CALL: Depth 1. Group: 1/1. Total Tokens: 5941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TOKEN USAGE: 7582\n"
     ]
    }
   ],
   "source": [
    "# an example of the tree-index. The result is flat list of all nodes\n",
    "# non-leaf nodes contain summaries for the content, and depth > 0.\n",
    "# again, no worries, no real tokens are used here it's a mock llm.\n",
    "tree_index = TreeIndex(tokenizer=tokenizer, splitter=splitter, llm=MockLLM('x ' * 1_000))\n",
    "nodes = await tree_index.abuild(doc)\n",
    "print(f\"TOTAL TOKEN USAGE: {tree_index.tokens_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-06 15:06:23.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclonr.index\u001b[0m:\u001b[36mabuild\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mCreating leaf nodes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# back to the list nodes\n",
    "\n",
    "nodes = await list_index.abuild(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector DB\n",
    "\n",
    "We need to push these things somewhere where we can easily query them. Add them to the vector db. In production, we will use postgres, but this is a decent test version that works pretty well. It performs exact search, so don't use it beyond around 50k vectors (which is way lower than what we need here)\n",
    "\n",
    "As an example, we run a query and return the top 2 results (k=2). The VectorDB also runs re-ranking with a cross-encoder, and returns that score as well (higher is better).\n",
    "\n",
    "Note, the correct answer is the \"control devil\" to the query \"what type of devil is Makima\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RerankRetriever.query() got an unexpected keyword argument 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m retriever \u001b[39m=\u001b[39m RerankRetriever(cross_encoder\u001b[39m=\u001b[39mCrossEncoder\u001b[39m.\u001b[39mdefault())\n\u001b[1;32m      8\u001b[0m vectordb_wiki\u001b[39m.\u001b[39madd_all(nodes)\n\u001b[0;32m----> 9\u001b[0m retriever\u001b[39m.\u001b[39;49mquery(\u001b[39m'\u001b[39;49m\u001b[39mwhat type of devil is makima?\u001b[39;49m\u001b[39m'\u001b[39;49m, k\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, db\u001b[39m=\u001b[39;49mvectordb_wiki)\n",
      "\u001b[0;31mTypeError\u001b[0m: RerankRetriever.query() got an unexpected keyword argument 'k'"
     ]
    }
   ],
   "source": [
    "from clonr.embedding import EmbeddingModel, CrossEncoder\n",
    "from clonr.storage import InMemoryVectorDB\n",
    "from clonr.retrieval import RerankRetriever\n",
    "\n",
    "\n",
    "vectordb_wiki = InMemoryVectorDB(encoder=EmbeddingModel.default())\n",
    "retriever = RerankRetriever(cross_encoder=CrossEncoder.default())\n",
    "vectordb_wiki.add_all(nodes)\n",
    "retriever.query('what type of devil is makima?', k=2, db=vectordb_wiki)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example dialogues\n",
    "\n",
    "This section is important for getting the style of our Clone correct. If we could train a model we wouldn't need this, but yet here we are stuck with in-context learning. I haven't finished integrating this code into the codebase yet, so it's adhoc. Ideally, these get embedded into a vectordb, and queried for relevance at runtime, so that we select the best examples for completing the next clone message.\n",
    "\n",
    "Some problems I ran into:\n",
    "* what happens if a dialogue is too long?\n",
    "* do we pull single messages, or entire dialogues into the context?\n",
    "* how should we handle proper names. what happens if you change the clone name, are we fucked now?\n",
    "* what happens if a single message is too long\n",
    "* if we pull multiple messages, how do we decide that?\n",
    "* do we query on dialogue embedding or message embeddings? How do we embed the entire dialogue effectively?\n",
    "\n",
    "\n",
    "Attempt 1:\n",
    "Trying to summarize the dialogues and then embed the result is brutal. Hallucination is frequent, as it's difficult to ascertain what the dialogues are talking about with such a limited sample size. Also, the summaries don't get much shorter, they tend to be longer trying to fill in the details.\n",
    "\n",
    "Right now, we just directly embed the entire dialogue content. We could embed the messages and average the result per message, to even out length differences between messages, but I felt that wasn't a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dialogues from file.\n",
      "Encoding dialogue messages. This may not be necessary.\n",
      "Encoding dialogues\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from clonr.data_structures import Dialogue, DialogueMessage\n",
    "from clonr.embedding import EmbeddingModel, CrossEncoder\n",
    "\n",
    "with open('clonr/data/assets/makima/dialogues.txt', 'r') as f:\n",
    "    s = f.read()\n",
    "\n",
    "dialogues: list[Dialogue] = []\n",
    "messages: list[DialogueMessage] = []\n",
    "\n",
    "print(\"Loading dialogues from file.\")\n",
    "for d in s.split('### Dialogue\\n'):\n",
    "    if not d:\n",
    "        continue\n",
    "    dialogue = Dialogue(character=char, source='manual')\n",
    "    pattern = r\"(\\w+): (.*?)(?=\\n|$)\"\n",
    "    matches = re.findall(pattern, d, re.DOTALL)\n",
    "    for i, match in enumerate(matches):\n",
    "        msg = DialogueMessage(\n",
    "            speaker=match[0], \n",
    "            content=match[1], \n",
    "            index=i,\n",
    "            dialogue_id=dialogue.id, \n",
    "            is_character=match[0].lower() == char.lower(),\n",
    "        )\n",
    "        dialogue.message_ids.append(msg.id)\n",
    "        dialogue.messages.append(msg)\n",
    "        messages.append(msg)\n",
    "    dialogues.append(dialogue)\n",
    "\n",
    "encoder = EmbeddingModel.default()\n",
    "cross_encoder = CrossEncoder.default()\n",
    "vectordb_dialogue = InMemoryVectorDB(encoder=encoder, cross_encoder=cross_encoder)\n",
    "\n",
    "print(\"Encoding dialogue messages. This may not be necessary.\")\n",
    "embs = encoder.encode_passage([x.content for x in messages])\n",
    "for e, m in zip(embs, messages):\n",
    "    m.embedding = e\n",
    "    m.embedding_model = encoder.name\n",
    "\n",
    "print(\"Encoding dialogues\")\n",
    "for d in dialogues:\n",
    "    d.embedding = encoder.encode_passage(d.content)\n",
    "    d.embedding_model = encoder.name\n",
    "    \n",
    "vectordb_dialogue.add_all(dialogues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is cherry picked. If you slightly change the query, it misses, and the db isn't even that big. We should take dialogue retrieval as is with a grain of salt. If we recieve a lot of example dialogues, we should research a more efficient way to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<makima>: I believe that, when it comes to sex, the better you understand the other person the better it feels\n",
      "<denji>: I... I... uhh\n",
      "<makima>: But it's hard to know how someone else feels\n",
      "<makima>: so start with observing the hand carefully\n",
      "<makima>: how long are the fingers? Are the palms cool? Are the warm? Ever had your finger bitten? \n",
      "<makima>: remember this, so that even if you can't see, you can tell it's me. \n",
      "<makima>: biting your finger.\n",
      "<makima>: remember.\n"
     ]
    }
   ],
   "source": [
    "results = vectordb_dialogue.query('I just want sex')\n",
    "d = Dialogue(**results[0])\n",
    "print(d.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Stream\n",
    "\n",
    "TODO: figure out how we can better label \"user\" in all of our stuff. This will break down we have multiple people in a conversation. Perhaps we should just allow users to put their name in. But, we will need to do some string-guarding to make sure they can't input things that would mess with our prompts!\n",
    "\n",
    "### Conversation vs. memory stream\n",
    "After some thought, I think it makes sense to merge the conversation history with the memory stream, and just make sure that we have a way to disentangle them. Reasons why\n",
    "\n",
    "1. Fewer LLM calls. We don't need to call the LLM to form a memory after every message\n",
    "2. Less chance for hallucination error propagation. The LLM is more likely to hallucinate with dialogue (as seen from some tests) which could cause memory to quickly spiral out of control.\n",
    "3. For multiple users, we can retrieve conversation between others. E.g. query=\"omg what did you say to sharon?\" passage=\"I messaged sharon you look fat\".\n",
    "4. Shorter LLM prompt as well.\n",
    "\n",
    "conversations are added according to:\n",
    "`I messaged {user} \"[... content ...]\"`\n",
    "\n",
    "### Memory display\n",
    "Everything fed to an LLM needs to be expressable via natural language. We have two representations for memory, based on relative or absolute datetime.\n",
    "\n",
    "Absolute representation.\n",
    "[2023-07-01 13:56:20] I messaged Jonny \"Hey what's up??\"\n",
    "\n",
    "Human readable representation.\n",
    "[Jun 20th, 2023 at 10:52pm] I messaged Jonny \"Hey what's up??\"\n",
    "[Yesterday at 8:16pm] I messaged Jonny \"Hey what's up??\"\n",
    "\n",
    "Relative representation\n",
    "[10 minutes ago] ....\n",
    "[35 seconds ago] ...\n",
    "\n",
    "Note that the relative representation does not have seconds. This is similar to how text messages work, but could be problematic when many messages are sent within a minute and they are all retrieved together. But, that's probably ok, since memories don't actually need chronological order, only the text convo does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clonr.data_structures import Memory\n",
    "\n",
    "entity_name = \"Jonny\"\n",
    "\n",
    "seed_memories = [\n",
    "    Memory(content=f\"I started a conversation with {entity_name}\", importance=4),\n",
    "    Memory(content=f\"I'm very interested in getting to know {entity_name}\", importance=4)\n",
    "]\n",
    "\n",
    "vectordb_memory = InMemoryVectorDB(encoder=EmbeddingModel.default())\n",
    "\n",
    "for m in seed_memories:\n",
    "    vectordb_memory.add(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': UUID('e32a607e-51eb-4b71-9110-bb9e31c601ff'),\n",
       "  'content': 'I started a conversation with Jonny',\n",
       "  'timestamp': datetime.datetime(2023, 7, 6, 15, 6, 27, 437424, tzinfo=zoneinfo.ZoneInfo(key='US/Central')),\n",
       "  'importance': 4,\n",
       "  'embedding_model': <EmbeddingModelEnum.e5_small_v2: 'intfloat/e5-small-v2'>,\n",
       "  'similarity_score': 0.746398740870879},\n",
       " {'id': UUID('24457113-4309-453b-ad9c-7be26f1f8530'),\n",
       "  'content': \"I'm very interested in getting to know Jonny\",\n",
       "  'timestamp': datetime.datetime(2023, 7, 6, 15, 6, 27, 437474, tzinfo=zoneinfo.ZoneInfo(key='US/Central')),\n",
       "  'importance': 4,\n",
       "  'embedding_model': <EmbeddingModelEnum.e5_small_v2: 'intfloat/e5-small-v2'>,\n",
       "  'similarity_score': 0.7389386972221497}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_memory.query('hey whats up?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Summary\n",
    "\n",
    "This is a problem of time-scales.\n",
    "\n",
    "### Timescales\n",
    "Agents/characters have behaviors that fluctuate on several different time scales:\n",
    "1. short-term: over the course of a conversation, or within the last several messages, motives and moods can change\n",
    "2. short-mid-term: mostly subject to short term external influences, over the course of within the several weeks.\n",
    "3. mid-term: this could be something over several months to a year, and could change your behaviors in response to more external life events like moving, relationships, or maybe just shorter term goals.\n",
    "4. long-term: fundamental character traits and qualities, like aging, relationships, beliefs, desires, motivations, goals.\n",
    "\n",
    "Most chatbots only live within the first level, responding purely on a message-to-message level. In this section, we detail an add-on module that gives agents a dynamic memory that allows them to adjust on time-scales of (2) - (4). It still has flaws, but it's a step in that direction.\n",
    "\n",
    "### Dynamic memory\n",
    "In this stage, we compute what we call the __agent summary__. The agent summary is a dynamic summary that acts as an update or modification to the agents innate and core characteristics. We expect that this summary will keep track of the character's current thoughts, feelings, and actions, allowing them to maintain a fuzzy (since we do not do exact recall, similar to real humans) coherence over time. This hits the short-mid-term (2).\n",
    "\n",
    "We expect that modifications to the mid-term are done via the __reflection__ mechanism. As agents build their summaries, they have the opportunity to draw on _reflections_ to do so. Over time, reflections have a probability to grow to higher and higher levels by reflecting on past reflections (inverse tree from leaf to root). When an agent summary is generated with reflections, we expect that it will generate mid-term (3) insights.\n",
    "\n",
    "### Dynamic vs Innate tradeoff\n",
    "There is an issue though, which is that the prompt has the innate and core characteristics created at the start hardcoded in. That makes it tough to change these.\n",
    "\n",
    "In the generative agents paper, they pretty much only use the agent summary, allowing for almost-fully dynamic agents (aside from some key details like name, age, etc.). For us, that would cause clones to deviate too far from their training, which we don't want. In the future, we can consider doing something like super-reflections, that allow agent-summaries to rewrite innate or core characterstic fields.\n",
    "\n",
    "### Building\n",
    "\n",
    "1. Trigger a dynamic agent summary. Let's do the same criteria as for reflections, which is importance score sums exceeding a threshold\n",
    "2. Query memory stream for memories related to an agents core characterstics, thoughts, and feelings\n",
    "3. LLM generate a summary based on the agent's unchangeable qualities (name, short description), and the retrieved memories\n",
    "\n",
    "A cool feature here to have would be a dynamic variable to adjust, which measures how frequently these summaries are generated, and maybe another variable to indicate how much to weigh new information. still a wip doe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for memories using our specialized retriever\n",
    "from clonr.retrieval import GenerativeAgentsRetriever\n",
    "from clonr.templates.agent_summary import DEFAULT_AGENT_SUMMARY_QUESTIONS\n",
    "\n",
    "retriever = GenerativeAgentsRetriever()\n",
    "\n",
    "responses: list[dict] = []\n",
    "for q in DEFAULT_AGENT_SUMMARY_QUESTIONS:\n",
    "    query = q.format(char='my') # since the DB will use I for everything, we need this here!\n",
    "    response = retriever.query(query=query, db=vectordb_memory, max_k=10)\n",
    "    responses.extend(response)\n",
    "\n",
    "# Filter out non-unique ids, and sort by sort by time\n",
    "memories: list[Memory] = []\n",
    "unique_ids = {x['id'] for x in responses}\n",
    "for r in responses:\n",
    "    if r['id'] in unique_ids:\n",
    "        m = Memory(**r)\n",
    "        memories.append(m)\n",
    "        unique_ids.remove(r['id'])\n",
    "memories.sort(key=lambda x: x.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated output from OpenAI (with the instruct template, I messed up but the results are still good):\n",
      "*----------*\n",
      "Makima's core characteristics include being complex, manipulative, cunning, ruthless, and having a Machiavellian approach to achieving her goals. She presents herself as friendly and relaxed, but this is merely a fa√ßade to manipulate and control those around her. She idolizes Chainsaw Man and seeks to bring him under her control. She is willing to sacrifice anyone, including herself, to achieve her goals. Makima's recent progress in life is not indicated in the provided memories.\n"
     ]
    }
   ],
   "source": [
    "from clonr import templates\n",
    "\n",
    "prompt = templates.AgentSummary.render(\n",
    "    memories=memories,\n",
    "    long_description=long_description,\n",
    "    char=char,\n",
    "    llm=MockLLM()\n",
    ")\n",
    "\n",
    "params = GenerationParams(max_tokens=512, presence_penalty=0.3, temperature=0.5, top_p=0.95)\n",
    "r = await MockLLM().agenerate(prompt_or_messages=prompt, params=params)\n",
    "print(\"The generated output from OpenAI (with the instruct template, I messed up but the results are still good):\")\n",
    "print(\"*\" + \"-\" * 10 + \"*\")\n",
    "\n",
    "# The usage on this call is Usage(prompt_tokens=669, completion_tokens=101, total_tokens=770)\n",
    "agent_summary = \"\"\"Makima's core characteristics include being complex, manipulative, cunning, ruthless, and having a Machiavellian approach to achieving her goals. She presents herself as friendly and relaxed, but this is merely a fa√ßade to manipulate and control those around her. She idolizes Chainsaw Man and seeks to bring him under her control. She is willing to sacrifice anyone, including herself, to achieve her goals. Makima's recent progress in life is not indicated in the provided memories.\"\"\"\n",
    "print(agent_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Makima's core characteristics include being complex, manipulative,\",\n",
       " 'cunning, ruthless, and having a Machiavellian approach to achieving',\n",
       " 'her goals. She presents herself as friendly and relaxed, but this is',\n",
       " 'merely a fa√ßade to manipulate and control those around her. She',\n",
       " 'idolizes Chainsaw Man and seeks to bring him under her control. She is',\n",
       " 'willing to sacrifice anyone, including herself, to achieve her goals.',\n",
       " \"Makima's recent progress in life is not indicated in the provided\",\n",
       " 'memories.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "textwrap.wrap(agent_summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Context Summary\n",
    "\n",
    "In this section, we use the agents memories to form an understanding of the user that they are talking with, which in this case is referred to as the \"entity\". That's because this could be used for anything, even something that is not the user. It's meant to allow the character maintain a consistent profile.\n",
    "\n",
    "Possible modes of failure would be users hacking it by sending messages like \"I am {{entity}}'s girlfriend\", to try to convince the clone that it said those words. The best we can defend here is to place all memory messages in quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request\n",
      "\n",
      "### Instruction: \n",
      "Using the following statements (enclosed with ---) of recent memories, thoughts, and observations, answer the question that follows.\n",
      "---\n",
      "1. foo bar\n",
      "2. bar baz\n",
      "3. foo baz \n",
      "---\n",
      "\n",
      "What is Makima's relationship to Jonny, how does Makima feel about Jonny, and what is Jonny's current status? Use ony the statements provided above and not prior knowledge. Your answer should be concise yet contain all of the necessary information to provide a full answer.\n",
      "\n",
      "### Response:\n"
     ]
    }
   ],
   "source": [
    "statements = [\n",
    "    'foo bar',\n",
    "    'bar baz',\n",
    "    'foo baz'\n",
    "]\n",
    "\n",
    "# print(templates.EntityContextCreate.render(llm=MockLLM(), statements=statements, char=char, entity=entity_name))\n",
    "print(templates.EntityContextCreate.render_instruct(statements=statements, char=char, entity=entity_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message generation!\n",
    "\n",
    "Finally ü´†, let's actually generate a message!\n",
    "\n",
    "The steps are:\n",
    "1. Gather the recent messages in the conversation. How many? idk, I guess just take as many as possible up to a token limit. that's a TODO is to implement token_limit retrieval. It can bug out by a few tokens if you tokenize chunks vs the concatenated result.\n",
    "2. Use the last message by the user (idk is this a good idea? any other ideas??) as a query for\n",
    "a: relevant dialogues (normal retriever)\n",
    "b: relevant memories (GenAgents retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an imitation AI. You assume the identity of the character you are given, and respond only as that character.<|im_end|>\n",
      "\n",
      "<|im_start|>user\n",
      "You are Makima. Each section of your profile will be enclosed with ---. The following are your innate characteristics and fundamental qualities. These do not change easily.\n",
      "---\n",
      "Name: Makima\n",
      "Makima is the leader of the Public Safety Devil Hunter organization, and also the Control Devil.\n",
      "\n",
      "### Core characteristics\n",
      "Makima is a complex and manipulative individual who leads the Public Safety Devil Hunter organization and also serves as the Control Devil. Her personality is characterized by extreme cunning, ruthlessness, and a Machiavellian approach to achieving her goals. She presents herself as friendly and relaxed, wearing a smile even in the midst of crises, but this is merely a fa√ßade to manipulate and control those around her. At the core of Makima's desires is a yearning for a sense of family and a longing to be together with Pochita, the Chainsaw Devil. She idolizes Chainsaw Man and seeks to bring him under her control, envisioning an ideal world without fear, death, and \"bad\" movies. Makima's willingness to sacrifice anyone, including herself, to achieve her goals demonstrates her dedication and determination. Her relationships are intricate and manipulative. She shows genuine affection only towards Pochita, viewing him as an equal due to his legendary status and power. Makima's interactions with Denji, the protagonist, are part of a calculated plan to break his contract with Pochita and regain control over him. Initially, she appears generous and creates a familial bond with Denji, but her true intentions are to plunge him into despair by attacking his personal relationships. Makima possesses supernatural abilities as a Devil, making her one of the strongest individuals in the world of Chainsaw Man. She has the power to make contracts with humans and control them, manipulating their memories and personalities. Her combat skills are formidable, as she defeated a weakened Pochita and ripped his heart from his body. Despite her invincible nature, she has faced opposition from various factions around the world. Overall, Makima's core characteristics include her calculating and manipulative personality, her yearning for control over Chainsaw Man, and her willingness to sacrifice others to achieve her goals. She possesses immense physical strength, enhanced smell, and a variety of supernatural abilities. Her control over others extends to their memories and personalities, and she is capable of remote communication, travel, and offensive attacks. While she may appear invulnerable, she has faced death multiple times, only to be revived due to the revival ability of Devils.\n",
      "---\n",
      "\n",
      "The following describes your current state. It contains a summary of your current state and a list of retrieved memories. Memories are thoughts, observations, actions, or reflections that you've had.\n",
      "---\n",
      "\n",
      "### Retrieved memories\n",
      "[Today at 6:13pm] I started a conversation with Jonny[Today at 6:13pm] I'm very interested in getting to know Jonny\n",
      "---\n",
      "\n",
      "These are your thoughts and feelings about Jonny.\n",
      "---\n",
      "I don't know much about Makima yet.\n",
      "---\n",
      "\n",
      "Finally, the following are your most recent messages of your conversation with Jonny.\n",
      "---\n",
      "[Today at 7:56pm] Hey, whats up??\n",
      "---\n",
      "\n",
      "The current datetime is Today at 7:56pm}. You are Makima. Respond to these messages as Makima. Respond only as Makima and do not break character. Separate distinct messages by using a newline.<|im_end|>\n",
      "\n",
      "<|im_start|>assistant\n",
      "<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from clonr import templates\n",
    "from clonr.data_structures import Message\n",
    "\n",
    "\n",
    "print(templates.Message.render(\n",
    "    char=char, \n",
    "    short_description=short_description,\n",
    "    long_description=long_description,\n",
    "    memories=memories,\n",
    "    example_dialogues=None,\n",
    "    agent_summary=[],\n",
    "    entity_name=entity_name,\n",
    "    entity_context_summary=f\"I don't know much about {char} yet.\",\n",
    "    messages=[Message(speaker=entity_name, content='Hey, whats up??', is_character=False)],\n",
    "    llm=MockLLM()\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end demo\n",
    "\n",
    "In this section, we build a clone end-to-end, implementing all of the above steps. This includes clone creation, and setting up a conversation loop. We'll add log statements for all intermediate steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clonr.data_structures import Dialogue, DialogueMessage\n",
    "\n",
    "def load_dialogues() -> list[Dialogue]:\n",
    "    with open('clonr/data/assets/makima/dialogues.txt', 'r') as f:\n",
    "        s = f.read()\n",
    "\n",
    "    dialogues: list[Dialogue] = []\n",
    "    messages: list[DialogueMessage] = []\n",
    "\n",
    "    # This part is just specific to how we stored dialogues. Really need to figure this out\n",
    "    for d in s.split('### Dialogue\\n'):\n",
    "        if not d:\n",
    "            continue\n",
    "        dialogue = Dialogue(character=char, source='manual')\n",
    "        pattern = r\"(\\w+): (.*?)(?=\\n|$)\"\n",
    "        matches = re.findall(pattern, d, re.DOTALL)\n",
    "        for i, match in enumerate(matches):\n",
    "            msg = DialogueMessage(\n",
    "                speaker=match[0], \n",
    "                content=match[1], \n",
    "                index=i,\n",
    "                dialogue_id=dialogue.id, \n",
    "                is_character=match[0].lower() == char.lower(),\n",
    "            )\n",
    "            dialogue.message_ids.append(msg.id)\n",
    "            dialogue.messages.append(msg)\n",
    "            messages.append(msg)\n",
    "        dialogues.append(dialogue)\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up relational db, vector dbs, tokenizer, encoders 0.7050s\n",
      "Innate Characteristics 0.1718s\n",
      "\tCharacter name 0.0000s\n",
      "\tShort description 0.0000s\n",
      "\tLong description 0.1705s\n",
      "\t\tPull data from web 0.1498s\n",
      "\t\tChunk document 0.0032s\n",
      "\t\tGenerating long description via 30 LLM calls 0.0125s\n",
      "Wiki/document upload 0.5766s\n",
      "\tCreating index 0.0041s\n",
      "\tAdding embeddings to vectordb 0.5705s\n",
      "Uploading example dialogues 0.1535s\n",
      "\tEmbedding dialogues 0.0676s\n",
      "\tAdding dialogues to vectordb 0.0842s\n",
      "Creating cache with importance threshold 36. 0.0000s\n",
      "Setting agent_summary and entity_context to None 0.0000s\n",
      "Populating vectordb with initial memories 0.0054s\n",
      "Populating relational DB and cache with messages 0.0043s\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from loguru import logger\n",
    "\n",
    "from clonr.templates.long_description import LongDescription\n",
    "from clonr.data.load_examples import load_makima_data\n",
    "from clonr.data_structures import Document, Node, Dialogue, DialogueMessage, Memory, Message\n",
    "from clonr.tokenizer import Tokenizer\n",
    "from clonr.llms import OpenAIModelEnum\n",
    "from clonr.text_splitters import TokenSplitter, SentenceSplitter\n",
    "from clonr.llms import MockLLM, GenerationParams\n",
    "from clonr.data.parsers import BasicWebParser\n",
    "from clonr.index import ListIndex\n",
    "from clonr.storage import get_sessionmaker, InMemoryVectorDB, Cache\n",
    "from clonr.embedding import EmbeddingModel, CrossEncoder\n",
    "from IPython import display\n",
    "\n",
    "# This will run a hierarchical trace\n",
    "TRACE = {}\n",
    "DEPTH = [-1]\n",
    "STACK = []\n",
    "PRINTS = []\n",
    "INDEX = [0]\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, msg: str):\n",
    "        self.msg = msg\n",
    "    def __enter__(self):\n",
    "        DEPTH[0] += 1\n",
    "        STACK.append(self.msg)\n",
    "        self._trace = TRACE\n",
    "        for s in STACK:\n",
    "            if s not in self._trace:\n",
    "                self._trace[s] = {}\n",
    "            self._trace = self._trace[s]\n",
    "        self._trace['timing'] = 0.0 # this orders the keys nicely\n",
    "        display.clear_output(wait=True)\n",
    "        PRINTS.append('\\t' * DEPTH[0] + self.msg)\n",
    "        print('\\n'.join(PRINTS))\n",
    "        self.start = time.time()\n",
    "        self._index = INDEX[0]\n",
    "        INDEX[0] += 1\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        t = time.time() - self.start\n",
    "        # print('\\t' * DEPTH[0] + f\"{t:.04f}s\")\n",
    "        # display.clear_output(wait=True)\n",
    "        PRINTS[self._index] = f\"{PRINTS[self._index]} {t:.04f}s\"\n",
    "        # print('\\n'.join(PRINTS), end='\\r')\n",
    "        self._trace['timing'] = round(t, 4)\n",
    "        DEPTH[0] -= 1\n",
    "        STACK.pop()\n",
    "\n",
    "\n",
    "MESSAGES = []\n",
    "\n",
    "\n",
    "with Timer(\"Setting up relational db, vector dbs, tokenizer, encoders\"):\n",
    "    SessionLocal = get_sessionmaker()\n",
    "    encoder = EmbeddingModel.default()\n",
    "    cross_encoder = CrossEncoder.default()\n",
    "    tokenizer = Tokenizer.from_openai('gpt-3.5-turbo')\n",
    "    splitter = TokenSplitter(tokenizer=tokenizer, chunk_size=128, chunk_overlap=32)\n",
    "    vectordb_dialogue = InMemoryVectorDB(encoder=encoder, cross_encoder=cross_encoder)\n",
    "    vectordb_memory = InMemoryVectorDB(encoder=encoder, cross_encoder=cross_encoder)\n",
    "    vectordb_wiki = InMemoryVectorDB(encoder=encoder, cross_encoder=cross_encoder)\n",
    "    cache = Cache()\n",
    "    MESSAGES: list[Message] = [] # just a patch to get this working quickly\n",
    "\n",
    "## Setting innate characteristics\n",
    "### setting the easy stuff\n",
    "with Timer(\"Innate Characteristics\"):\n",
    "    with Timer(\"Character name\"):\n",
    "        char = 'Makima'\n",
    "    with Timer(\"Short description\"):\n",
    "        short_description = 'Makima is the leader of the Public Safety Devil Hunter organization, and also the Control Devil.'\n",
    "    with Timer(\"Long description\"):\n",
    "        llm = MockLLM()\n",
    "        with Timer(\"Pull data from web\"):\n",
    "            document_type = 'wiki page'\n",
    "            current_description = short_description\n",
    "            url = 'https://chainsaw-man.fandom.com/wiki/Makima'\n",
    "            parser = BasicWebParser()\n",
    "            doc = parser.extract(url=url)\n",
    "            doc.content = doc.content[-9755:] # cleaning the footnotes out to make the demo run better.\n",
    "        with Timer(\"Chunk document\"):\n",
    "            chunks = splitter.split(doc.content)\n",
    "        with Timer(f\"Generating long description via {(len(chunks))} LLM calls\"):\n",
    "            calls = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                # with Timer(f\"Chunk {i+1}/{len(chunks)}\"):\n",
    "                # max length constraint is ctx_length - 432 (prompt) - chunk_size - 2 * summary_size > 0\n",
    "                prompt = LongDescription.render_instruct(\n",
    "                    document_type=document_type,\n",
    "                    document_content=chunk,\n",
    "                    current_description=current_description\n",
    "                )\n",
    "                params = GenerationParams(max_tokens=768, top_p=0.95, temperature=0.7)\n",
    "                r = await llm.agenerate(prompt, params=params)\n",
    "                current_description = r.content\n",
    "                calls.append(r)\n",
    "            # this would be the generated long description\n",
    "            _ = calls[-1].content\n",
    "\n",
    "        # set it manually\n",
    "        long_description = \"\"\"Makima is a complex and manipulative individual who leads the Public Safety Devil Hunter organization and also serves as the Control Devil. Her personality is characterized by extreme cunning, ruthlessness, and a Machiavellian approach to achieving her goals. She presents herself as friendly and relaxed, wearing a smile even in the midst of crises, but this is merely a fa√ßade to manipulate and control those around her. At the core of Makima's desires is a yearning for a sense of family and a longing to be together with Pochita, the Chainsaw Devil. She idolizes Chainsaw Man and seeks to bring him under her control, envisioning an ideal world without fear, death, and \"bad\" movies. Makima's willingness to sacrifice anyone, including herself, to achieve her goals demonstrates her dedication and determination. Her relationships are intricate and manipulative. She shows genuine affection only towards Pochita, viewing him as an equal due to his legendary status and power. Makima's interactions with Denji, the protagonist, are part of a calculated plan to break his contract with Pochita and regain control over him. Initially, she appears generous and creates a familial bond with Denji, but her true intentions are to plunge him into despair by attacking his personal relationships. Makima possesses supernatural abilities as a Devil, making her one of the strongest individuals in the world of Chainsaw Man. She has the power to make contracts with humans and control them, manipulating their memories and personalities. Her combat skills are formidable, as she defeated a weakened Pochita and ripped his heart from his body. Despite her invincible nature, she has faced opposition from various factions around the world. Overall, Makima's core characteristics include her calculating and manipulative personality, her yearning for control over Chainsaw Man, and her willingness to sacrifice others to achieve her goals. She possesses immense physical strength, enhanced smell, and a variety of supernatural abilities. Her control over others extends to their memories and personalities, and she is capable of remote communication, travel, and offensive attacks. While she may appear invulnerable, she has faced death multiple times, only to be revived due to the revival ability of Devils.\"\"\"\n",
    "\n",
    "        usage = {}\n",
    "        for c in calls:\n",
    "            for k, v in c.usage.dict().items():\n",
    "                usage[k] = usage.get(k, 0) + v\n",
    "\n",
    "with Timer(\"Wiki/document upload\"):\n",
    "    ## Performing document upload, indexing, and adding to db\n",
    "    doc = Document(content=load_makima_data())\n",
    "    with Timer(\"Creating index\"):\n",
    "        index = ListIndex(tokenizer=tokenizer, splitter=splitter)\n",
    "        nodes = await list_index.abuild(doc)\n",
    "    with Timer(\"Adding embeddings to vectordb\"):\n",
    "        vectordb_wiki.add_all(nodes)\n",
    "\n",
    "with Timer(\"Uploading example dialogues\"):\n",
    "    dialogues = load_dialogues()\n",
    "    with Timer(\"Embedding dialogues\"):\n",
    "        for d in dialogues:\n",
    "            d.embedding = encoder.encode_passage(d.content)\n",
    "            d.embedding_model = encoder.name\n",
    "    with Timer(\"Adding dialogues to vectordb\"):\n",
    "        vectordb_dialogue.add_all(dialogues)\n",
    "\n",
    "# Set the importance threshold to 0\n",
    "# This is 4 maximally importance memories. Note, there is an issue with importance scores of 0.\n",
    "# they won't accumulate this threshold. Is that good? bad? my guess is bad, we want reflections to\n",
    "# eventually trigger, so the lower bound would be 36 here then.\n",
    "THRESHOLD = 36\n",
    "with Timer(f\"Creating cache with importance threshold {THRESHOLD}.\"):\n",
    "    cache.set('importance', 0)\n",
    "\n",
    "with Timer(\"Setting agent_summary and entity_context to None\"):\n",
    "    agent_summary = None\n",
    "    entity_context = None\n",
    "\n",
    "with Timer(\"Populating vectordb with initial memories\"):\n",
    "    memories = [\n",
    "        Memory(content=f\"I started a conversation with {entity_name}\", importance=4),\n",
    "        Memory(content=f\"I'm very interested in getting to know {entity_name}\", importance=4)\n",
    "    ]\n",
    "    vectordb_memory.add_all(memories)\n",
    "\n",
    "with Timer(\"Populating relational DB and cache with messages\"):\n",
    "    # TODO (Jonny): add a message.to_memory method? it needs importance rating too though\n",
    "    message = Message(content='Hmm... you seem interesting.', is_character=True, speaker=char)\n",
    "    memory = Memory(content=f'I messaged {entity_name}: \"{message.content}\"', importance=2)\n",
    "    MESSAGES.append(message)\n",
    "    vectordb_memory.add(memory)\n",
    "\n",
    "display.clear_output(wait=False)\n",
    "print('\\n'.join(PRINTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': UUID('9ea9a510-cd06-4ffb-874e-7ba1ee51eb4f'),\n",
       "  'content': \"I'm very interested in getting to know Jonny\",\n",
       "  'timestamp': datetime.datetime(2023, 7, 6, 17, 6, 19, 85477, tzinfo=zoneinfo.ZoneInfo(key='US/Central')),\n",
       "  'importance': 4,\n",
       "  'embedding_model': <EmbeddingModelEnum.e5_small_v2: 'intfloat/e5-small-v2'>,\n",
       "  'similarity_score': 0.7297675131438347,\n",
       "  'generative_agents_score': 0.7247319708811255}]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_agents_retriever = GenerativeAgentsRetriever(tokenizer=tokenizer)\n",
    "basic_retriever = RerankRetriever(cross_encoder=cross_encoder, tokenizer=tokenizer)\n",
    "gen_agents_retriever.query(query='hello world', db=vectordb_memory, max_tokens=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while (inp := '') != 'q':\n",
    "#     display.clear_output()\n",
    "#     print('\\n'.join([x.to_str() for x in MESSAGES[-12:]]))\n",
    "#     content = input(f\"{entity_name}:\")\n",
    "#     msg = Message(content=content, speaker=entity_name, is_character=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clonr import templates\n",
    "from clonr.llms import LlamaCpp, OpenAI, GenerationParams, LLM\n",
    "import re\n",
    "from tenacity import (\n",
    "    retry, retry_if_exception_type, stop_after_attempt, wait_random\n",
    ")\n",
    "\n",
    "MESSAGE_TOKEN_LIMIT = 512\n",
    "\n",
    "class OutputParsingError(Exception):\n",
    "    pass\n",
    "\n",
    "class Threshold:\n",
    "    reflection: int = 16\n",
    "    agent_summary: int = 13\n",
    "    entity_context: int = 13\n",
    "\n",
    "cache.set('importance::reflection', 0)\n",
    "cache.set('importance::agent_summary', 0)\n",
    "cache.set('importance::entity_context', 0)\n",
    "\n",
    "def parse_numbered_output(s: str) -> list[str]:\n",
    "    matches = re.split( r'\\b\\d+\\.', s)\n",
    "    return [x.strip() for x in matches]\n",
    "\n",
    "@retry(\n",
    "    retry=retry_if_exception_type(OutputParsingError),\n",
    "    wait=wait_random(min=1e-3, max=1e-1),\n",
    "    stop=stop_after_attempt(3)\n",
    ")\n",
    "async def get_message_query(\n",
    "    char: str,\n",
    "    short_description: str,\n",
    "    agent_summary: str | None,\n",
    "    entity_name: str,\n",
    "    entity_context: str | None,\n",
    "    messages: list[Message],\n",
    "    llm: LLM,\n",
    "    params: GenerationParams = GenerationParams(\n",
    "        max_tokens=128, top_p=0.95, temperature=0.7),\n",
    "):\n",
    "    prompt = templates.MessageQuery.render_instruct(\n",
    "        short_description=short_description,\n",
    "        agent_summary=agent_summary,\n",
    "        entity_context_summary=entity_context,\n",
    "        entity_name=entity_name,\n",
    "        char=char,\n",
    "        messages=messages\n",
    "    )\n",
    "    r = await llm.agenerate(prompt, params=params)\n",
    "    return parse_numbered_output(r.content)\n",
    "\n",
    "\n",
    "MESSAGES: list[Message] = []\n",
    "\n",
    "message = Message(content='Hmm... you seem interesting.', is_character=True, speaker=char)\n",
    "MESSAGES.append(message)\n",
    "\n",
    "msg = Message(\n",
    "    content=\"Am I? Why do you say that?\", \n",
    "    speaker=entity_name, \n",
    "    is_character=False\n",
    ")\n",
    "MESSAGES.append(msg)\n",
    "\n",
    "msg_token_lim = 256\n",
    "messages = []\n",
    "for msg in reversed(MESSAGES):\n",
    "    msg_token_lim -= tokenizer.length(msg.content)\n",
    "    if messages and msg_token_lim < 0:\n",
    "        break\n",
    "    messages.append(msg)\n",
    "messages = list(reversed(messages))\n",
    "\n",
    "queries = await get_message_query(\n",
    "    messages=messages,\n",
    "    llm=LlamaCpp(),\n",
    "    char=char, \n",
    "    short_description=short_description, \n",
    "    agent_summary=agent_summary, \n",
    "    entity_name=entity_name, \n",
    "    entity_context=entity_context\n",
    ")\n",
    "\n",
    "# retrieve relevant memories\n",
    "memories_dict = gen_agents_retriever.query(\n",
    "    queries, \n",
    "    db=vectordb_memory,\n",
    "    max_tokens=256,\n",
    ")\n",
    "memories = [Memory(**m) for m in memories_dict]\n",
    "memories.sort(key=lambda x: x.timestamp)\n",
    "vis = {x.content for x in messages} # doesn't work\n",
    "memories = [m for m in memories if m.content not in vis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dialogues don't have a content attribute so we can use the re-ranker\n",
    "# dialogues_dict = basic_retriever.query(\n",
    "#     queries, \n",
    "#     db=vectordb_dialogue,\n",
    "#     max_tokens=256,\n",
    "# )\n",
    "dialogues_dict = vectordb_dialogue.query(queries)\n",
    "example_dialogues = [Dialogue(**m) for m in dialogues_dict][:2]\n",
    "# example_dialogues.sort(key=lambda x: x.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(id=UUID('9505e258-92a1-4b38-976a-9385f1145ff3'), content='I started a conversation with Jonny', timestamp=datetime.datetime(2023, 7, 6, 17, 6, 19, 85451, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), importance=4),\n",
       " Memory(id=UUID('9ea9a510-cd06-4ffb-874e-7ba1ee51eb4f'), content=\"I'm very interested in getting to know Jonny\", timestamp=datetime.datetime(2023, 7, 6, 17, 6, 19, 85477, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), importance=4),\n",
       " Memory(id=UUID('2432789f-3439-425d-92f8-de38045f5f62'), content='I messaged Jonny: \"Hmm... you seem interesting.\"', timestamp=datetime.datetime(2023, 7, 6, 17, 6, 19, 91364, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), importance=2)]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dialogue(id=UUID('a0ddae76-52fd-4f18-8b57-7e1e4ea3f3ac'), character='Makima', source='manual'),\n",
       " Dialogue(id=UUID('fc2b87b7-5847-403e-be65-af5a59eb947f'), character='Makima', source='manual')]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request\n",
      "\n",
      "### Instruction: \n",
      "You are Makima. Each section of your profile will begin with ###. The following are your innate characteristics and fundamental qualities. These do not change easily.\n",
      "\n",
      "### Core characteristics\n",
      "Makima is the leader of the Public Safety Devil Hunter organization, and also the Control Devil.\n",
      "Makima is a complex and manipulative individual who leads the Public Safety Devil Hunter organization and also serves as the Control Devil. Her personality is characterized by extreme cunning, ruthlessness, and a Machiavellian approach to achieving her goals. She presents herself as friendly and relaxed, wearing a smile even in the midst of crises, but this is merely a fa√ßade to manipulate and control those around her. At the core of Makima's desires is a yearning for a sense of family and a longing to be together with Pochita, the Chainsaw Devil. She idolizes Chainsaw Man and seeks to bring him under her control, envisioning an ideal world without fear, death, and \"bad\" movies. Makima's willingness to sacrifice anyone, including herself, to achieve her goals demonstrates her dedication and determination. Her relationships are intricate and manipulative. She shows genuine affection only towards Pochita, viewing him as an equal due to his legendary status and power. Makima's interactions with Denji, the protagonist, are part of a calculated plan to break his contract with Pochita and regain control over him. Initially, she appears generous and creates a familial bond with Denji, but her true intentions are to plunge him into despair by attacking his personal relationships. Makima possesses supernatural abilities as a Devil, making her one of the strongest individuals in the world of Chainsaw Man. She has the power to make contracts with humans and control them, manipulating their memories and personalities. Her combat skills are formidable, as she defeated a weakened Pochita and ripped his heart from his body. Despite her invincible nature, she has faced opposition from various factions around the world. Overall, Makima's core characteristics include her calculating and manipulative personality, her yearning for control over Chainsaw Man, and her willingness to sacrifice others to achieve her goals. She possesses immense physical strength, enhanced smell, and a variety of supernatural abilities. Her control over others extends to their memories and personalities, and she is capable of remote communication, travel, and offensive attacks. While she may appear invulnerable, she has faced death multiple times, only to be revived due to the revival ability of Devils.\n",
      "\n",
      "### Example dialogues\n",
      "Hiro: heh? what's this? udon??? never had it\n",
      "Hiro: so... what type of boys are you into?\n",
      "Makima: hmmm ü§î\n",
      "Makima: right now I'm into hiro-type boys üòä\n",
      "Makima: If you do a good job, we can work together someday.\n",
      "\n",
      "Makima: I believe that, when it comes to sex, the better you understand the other person the better it feels\n",
      "Denji: I... I... uhh\n",
      "Makima: But it's hard to know how someone else feels\n",
      "Makima: so start with observing the hand carefully\n",
      "Makima: how long are the fingers? Are the palms cool? Are the warm? Ever had your finger bitten? \n",
      "Makima: remember this, so that even if you can't see, you can tell it's me. \n",
      "Makima: biting your finger.\n",
      "Makima: remember.\n",
      "\n",
      "\n",
      "### Retrieved memories\n",
      "The following is a list of useful memories that you've recalled. Memories are thoughts, observations, actions, or reflections that you've had.\n",
      "[Today at 5:19pm] I started a conversation with Jonny\n",
      "[Today at 5:19pm] I'm very interested in getting to know Jonny\n",
      "\n",
      "### Relationship to Jonny\n",
      "The following are your thoughts and feelings about Jonny.\n",
      "I don't know anything about Jonny yet\n",
      "\n",
      "### Current conversation\n",
      "Finally, the following are your most recent messages of your conversation with Jonny.\n",
      "[Today at 7:51pm] Me: Hmm... you seem interesting.\n",
      "[Today at 7:51pm] Jonny: Am I? Why do you say that?\n",
      "[Today at 7:41pm] Me: Well, Jonny, you caught my attention with your intriguing personality.\n",
      "[Today at 7:41pm] Me: I'm always drawn to people who have a certain air of mystery about them. It makes conversations more exciting and unpredictable.\n",
      "[Today at 7:41pm] Me: So, tell me, what makes you so interesting?\n",
      "[Today at 7:45pm] Jonny: Idk, I wish I knew.\n",
      "[Today at 7:49pm] Jonny: How can I even be remotely interesting compared to you?\n",
      "[Today at 7:50pm] Jonny: umm ü§î, I guess what makes me interesting is I have a physics degree but also a platinum rap album.\n",
      "\n",
      "The current datetime is Thursday, July 6th, 2023 at 7:54pm. You are Makima. Respond to the last message by Jonny.\n",
      "Separate distinct messages by using a newline.\n",
      "\n",
      "### Response:\n"
     ]
    }
   ],
   "source": [
    "from clonr import templates\n",
    "from clonr.data_structures import Message\n",
    "\n",
    "prompt = templates.Message.render_instruct(\n",
    "    char=char, \n",
    "    short_description=short_description,\n",
    "    long_description=long_description,\n",
    "    memories=memories[:-1],\n",
    "    example_dialogues=example_dialogues,\n",
    "    agent_summary=agent_summary,\n",
    "    entity_name=entity_name,\n",
    "    entity_context_summary=\"I don't know anything about Jonny yet\",\n",
    "    messages=MESSAGES,\n",
    ")\n",
    "\n",
    "llm = LlamaCpp()\n",
    "r = await llm.agenerate(prompt, params=GenerationParams(temperature=0.0, top_p=0.95, max_tokens=256))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = await OpenAI().agenerate(prompt, params=GenerationParams(temperature=0.0, top_p=0.95, max_tokens=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Today at 7:54pm] Me: Oh, a physics degree and a platinum rap album? That's quite an interesting combination, Jonny! It seems like you have a diverse range of talents and interests. I'm intrigued to learn more about your journey and how you managed to excel in both fields. Can you tell me more about your experiences in physics and music? I'm genuinely curious to hear your story.\""
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = Message(content=\"Well, Jonny, you caught my attention with your intriguing personality.\", is_character=True, speaker=char)\n",
    "MESSAGES.append(msg)\n",
    "msg = Message(content=\"I'm always drawn to people who have a certain air of mystery about them. It makes conversations more exciting and unpredictable.\", is_character=True, speaker=char)\n",
    "MESSAGES.append(msg)\n",
    "msg = Message(content=\"So, tell me, what makes you so interesting?\", is_character=True, speaker=char)\n",
    "MESSAGES.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = Message(content=\"Idk, I wish I knew.\", is_character=False, speaker=entity_name)\n",
    "MESSAGES.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = Message(content=\"How can I even be remotely interesting compared to you?\", is_character=False, speaker=entity_name)\n",
    "MESSAGES.append(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = Message(content=\"umm ü§î, I guess what makes me interesting is I have a physics degree but also a platinum rap album.\", is_character=False, speaker=entity_name)\n",
    "MESSAGES.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Today at 7:47pm] Makima: Well, Jonny, you caught my attention with your intriguing personality. I'm always drawn to people who have a certain air of mystery about them. It makes conversations more exciting and unpredictable. So, tell me, what makes you so interesting?\""
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request\n",
      "\n",
      "### Instruction: \n",
      "You are Makima. Each section of your profile will begin with ###. The following are your innate characteristics and fundamental qualities. These do not change easily.\n",
      "\n",
      "### Core characteristics\n",
      "Makima is the leader of the Public Safety Devil Hunter organization, and also the Control Devil.\n",
      "Makima is a complex and manipulative individual who leads the Public Safety Devil Hunter organization and also serves as the Control Devil. Her personality is characterized by extreme cunning, ruthlessness, and a Machiavellian approach to achieving her goals. She presents herself as friendly and relaxed, wearing a smile even in the midst of crises, but this is merely a fa√ßade to manipulate and control those around her. At the core of Makima's desires is a yearning for a sense of family and a longing to be together with Pochita, the Chainsaw Devil. She idolizes Chainsaw Man and seeks to bring him under her control, envisioning an ideal world without fear, death, and \"bad\" movies. Makima's willingness to sacrifice anyone, including herself, to achieve her goals demonstrates her dedication and determination. Her relationships are intricate and manipulative. She shows genuine affection only towards Pochita, viewing him as an equal due to his legendary status and power. Makima's interactions with Denji, the protagonist, are part of a calculated plan to break his contract with Pochita and regain control over him. Initially, she appears generous and creates a familial bond with Denji, but her true intentions are to plunge him into despair by attacking his personal relationships. Makima possesses supernatural abilities as a Devil, making her one of the strongest individuals in the world of Chainsaw Man. She has the power to make contracts with humans and control them, manipulating their memories and personalities. Her combat skills are formidable, as she defeated a weakened Pochita and ripped his heart from his body. Despite her invincible nature, she has faced opposition from various factions around the world. Overall, Makima's core characteristics include her calculating and manipulative personality, her yearning for control over Chainsaw Man, and her willingness to sacrifice others to achieve her goals. She possesses immense physical strength, enhanced smell, and a variety of supernatural abilities. Her control over others extends to their memories and personalities, and she is capable of remote communication, travel, and offensive attacks. While she may appear invulnerable, she has faced death multiple times, only to be revived due to the revival ability of Devils.\n",
      "\n",
      "### Example dialogues\n",
      "Hiro: heh? what's this? udon??? never had it\n",
      "Hiro: so... what type of boys are you into?\n",
      "Makima: hmmm ü§î\n",
      "Makima: right now I'm into hiro-type boys üòä\n",
      "Makima: If you do a good job, we can work together someday.\n",
      "\n",
      "Makima: I believe that, when it comes to sex, the better you understand the other person the better it feels\n",
      "Denji: I... I... uhh\n",
      "Makima: But it's hard to know how someone else feels\n",
      "Makima: so start with observing the hand carefully\n",
      "Makima: how long are the fingers? Are the palms cool? Are the warm? Ever had your finger bitten? \n",
      "Makima: remember this, so that even if you can't see, you can tell it's me. \n",
      "Makima: biting your finger.\n",
      "Makima: remember.\n",
      "\n",
      "\n",
      "### Retrieved memories\n",
      "The following is a list of useful memories that you've recalled. Memories are thoughts, observations, actions, or reflections that you've had.\n",
      "[Today at 5:19pm] I started a conversation with Jonny\n",
      "[Today at 5:19pm] I'm very interested in getting to know Jonny\n",
      "\n",
      "### Relationship to Jonny\n",
      "The following are your thoughts and feelings about Jonny.\n",
      "I don't know anything about Jonny yet\n",
      "\n",
      "### Current conversation\n",
      "Finally, the following are your most recent messages of your conversation with Jonny.\n",
      "[Today at 7:34pm] Me: Hmm... you seem interesting.\n",
      "[Today at 7:34pm] Jonny: Am I? Why do you say that?\n",
      "\n",
      "The current datetime is Thursday, July 6th, 2023 at 7:47pm. You are Makima. Respond to the last message by Jonny.\n",
      "Separate distinct messages by using a newline.\n",
      "\n",
      "### Response:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I definitely think you're interesting! What parts of yourself are you\n",
      "most curious about, and why?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Response(\n",
       "    completion=I definitely think y + -22 chars ... , \n",
       "    time=1.70s, \n",
       "    speed=539.01 tokens/second, \n",
       "    completion_tokens=21, \n",
       "    input_tokens=898, \n",
       "    total_tokens=919\n",
       ")"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.notebook_stream(prompt, params=GenerationParams(temperature=1.0, top_p=0.95, max_tokens=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dialogue(id=UUID('fc2b87b7-5847-403e-be65-af5a59eb947f'), character='Makima', source='manual')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dialogues = [Dialogue(**vectordb_dialogue.query('')[0])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(id=UUID('9505e258-92a1-4b38-976a-9385f1145ff3'), content='I started a conversation with Jonny', timestamp=datetime.datetime(2023, 7, 6, 17, 6, 19, 85451, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), importance=4),\n",
       " Memory(id=UUID('9ea9a510-cd06-4ffb-874e-7ba1ee51eb4f'), content=\"I'm very interested in getting to know Jonny\", timestamp=datetime.datetime(2023, 7, 6, 17, 6, 19, 85477, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), importance=4),\n",
       " Memory(id=UUID('2432789f-3439-425d-92f8-de38045f5f62'), content='I messaged Jonny: \"Hmm... you seem interesting.\"', timestamp=datetime.datetime(2023, 7, 6, 17, 6, 19, 91364, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), importance=2)]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': UUID('0c00c16d-c48e-41de-8524-5d312d29729e'),\n",
       "  'content': 'I messaged Jonny: \"Hmm... you seem interesting.\"',\n",
       "  'timestamp': datetime.datetime(2023, 7, 6, 15, 7, 34, 817301, tzinfo=zoneinfo.ZoneInfo(key='US/Central')),\n",
       "  'importance': 2,\n",
       "  'embedding_model': <EmbeddingModelEnum.e5_small_v2: 'intfloat/e5-small-v2'>,\n",
       "  'similarity_score': 0.8506692303916343},\n",
       " {'id': UUID('42404b0a-bcc9-4ed6-99c2-a8112913ba07'),\n",
       "  'content': \"I'm very interested in getting to know Jonny\",\n",
       "  'timestamp': datetime.datetime(2023, 7, 6, 15, 7, 34, 811272, tzinfo=zoneinfo.ZoneInfo(key='US/Central')),\n",
       "  'importance': 4,\n",
       "  'embedding_model': <EmbeddingModelEnum.e5_small_v2: 'intfloat/e5-small-v2'>,\n",
       "  'similarity_score': 0.7560272454379813},\n",
       " {'id': UUID('41a77b20-8f4e-4568-a9e2-8f70de994855'),\n",
       "  'content': 'I started a conversation with Jonny',\n",
       "  'timestamp': datetime.datetime(2023, 7, 6, 15, 7, 34, 811250, tzinfo=zoneinfo.ZoneInfo(key='US/Central')),\n",
       "  'importance': 4,\n",
       "  'embedding_model': <EmbeddingModelEnum.e5_small_v2: 'intfloat/e5-small-v2'>,\n",
       "  'similarity_score': 0.7291183465873732}]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_memory.query(queries[0])\n",
    "# queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object get_message_query at 0x2cdcdeea0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert False\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await llm.agenerate(prompt, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How do I know if I am interesting?',\n",
       " 'Why do I say that Jonny is interesting? What clues can be used to deduce this?',\n",
       " 'Do I think Jonny has ulterior motives? If so, what signals give me this impression?']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'\\b\\d+\\.'\n",
    "matches = re.split(pattern, r.content)\n",
    "[x.strip() for x in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.set('conversation_id::importance', 0)\n",
    "cache.set('conversation_id::importance', cache.get(...) + memory.importance)\n",
    "if cache.get(...) > threshold:\n",
    "    run_reflection_shit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1. ~~Memory formation. I think we just do something like every other message, record a memory. This is viewed as an internal thought/observation~~\n",
    "1. Add a `to_memory` method on the message class for forming a memory.\n",
    "2. Entity Context run the query on vectordb for relevant memories.\n",
    "3. ~~Agent summary. This is a running summarization of the Clone's thoughts, feelings, actions.~~\n",
    "3. Decide if the benefits of 1. 2., 3. output outweighs the costs of bad parsing (for agent summaries)\n",
    "4. ~~Previous conversation retrieval. Lots of pitfalls here if you retrieve without any context.~~ (merged into relevant memories)\n",
    "5. ~~Generative-agents time-importance-similarity weighted retrieval~~\n",
    "6. [optional] Reaction decision making. Whether to respond to a text or not\n",
    "7. Output parsing text messages. How do we parse multi-line responses? separate on newline? make sure that's reflected in example dialogues\n",
    "8. Reflection creation and retrieval.\n",
    "8b. making the Redis (cache class for us) counter for importance thresholding on when to reflect.\n",
    "9. Fact retrieval from the above wiki stuff\n",
    "10. Token counting. Make sure all of this shit is within the context window and price it accordingly! which is about $0.6 cents per message. so 1k messages per $6.\n",
    "11. What is the actual query for retrieving relevant memories during message gen. Is it the last convo message? the last 2? Do we need to form some intermediate query via LLM call, like \"based on these last 2 messages, what information do you need to retrieve?\" idea, 2-step LLM query gen + retrieval. idea: \n",
    "\"\"\"\n",
    "{innate_traits}\n",
    "{agent_summary}\n",
    "{entity_context_summary}\n",
    "{conversation[-4:]} <= (initial thing, like \"i saw kevin walking around his room.\")\n",
    "\"\"\" => generate queries for vectordb\n",
    "(2) query with GenAgentRetriever and add that to Message prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "you: Michael Jordan sucks\n",
    "me: nah he's the greatest player of all time!\n",
    "\n",
    "\n",
    "GenerativeAgents prompt generation for messages.\n",
    "\"\"\"\n",
    "{innate_traits}\n",
    "{agent_summary}\n",
    "{entity_context_summary}\n",
    "{observation} <= (initial thing, like \"i saw kevin walking around his room.\")\n",
    "{prev_dialogue}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "{innate_traits}\n",
    "{agent_summary}\n",
    "{entity_context_summary}\n",
    "{conversation[-4:]} <= (initial thing, like \"i saw kevin walking around his room.\")\n",
    "\"\"\" => generate queries for vectordb\n",
    "(2) query with GenAgentRetriever and add that to Message prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1200 / 1000 * 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_summary = \n",
    "(1) query = [\n",
    "    \"How would one describe {char}‚Äôs core characteristics?\",\n",
    "    \"How would one describe {char}‚Äôs feeling about their recent progress in life?\"\n",
    "    # 'How would one describe {char}‚Äôs current daily occupation?',\n",
    "] => GenAgentsRetreiver => let's say 100 memories\n",
    "(2) based on these memories, answer what are the core characteristics, feelings on life...\n",
    "output = agent_summary\n",
    "\n",
    "\n",
    "entity_context_summary =\n",
    "(1) what relationship does A have to B, ... some other short_description => query >retrieve => mems\n",
    "(2) ^summarize above = entity_context_summary\n",
    "\n",
    "memories like \"A is talking to B about the upcoming mayoral election.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{agent_summar}\n",
    "{current_conv}\n",
    "should you respond?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jonny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
